{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 设置中文显示\nplt.rcParams[\u0027font.sans-serif\u0027] \u003d [\u0027Microsoft JhengHei\u0027]\nplt.rcParams[\u0027axes.unicode_minus\u0027] \u003d False\n\nimport math\nimport sklearn.metrics as skm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense\nfrom tensorflow.keras.layers import RepeatVector, TimeDistributed\nfrom tensorflow.keras.layers import ConvLSTM2D,Flatten\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n conv_lstm2d (ConvLSTM2D)    (None, 1, 5, 64)          50176     \n                                                                 \n flatten (Flatten)           (None, 320)               0         \n                                                                 \n repeat_vector (RepeatVector  (None, 24, 320)          0         \n )                                                               \n                                                                 \n lstm (LSTM)                 (None, 24, 200)           416800    \n                                                                 \n time_distributed (TimeDistr  (None, 24, 100)          20100     \n ibuted)                                                         \n                                                                 \n time_distributed_1 (TimeDis  (None, 24, 1)            101       \n tributed)                                                       \n                                                                 \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 487,177\nTrainable params: 487,177\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
            "actual.shape[0]:239, actual.shape[1]:24\nConv-LSTM: [269.165] 51.1, 68.5, 141.3, 153.3, 194.4, 247.5, 297.3, 340.3, 338.5, 301.5, 282.7, 283.8, 287.3, 299.7, 305.0, 300.0, 301.8, 297.6, 299.1, 297.7, 293.9, 302.4, 269.8, 234.7\n\n[40.25071097018829, 53.41814649254707, 95.87131592818383, 113.87799557482349, 146.7287137977249, 194.43395383188414, 234.44138786283995, 265.057767349307, 264.5890745538049, 231.853750572045, 215.5462600516475, 217.0230564771836, 214.94968762258108, 222.3302405449137, 228.38643681354603, 228.44687949463912, 233.5027182351595, 228.1081553183839, 230.55332072110355, 229.75592373006015, 228.44514701555963, 236.14545265101987, 207.07748042788964, 178.75016650594927]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def split_dataset(data):\n    \u0027\u0027\u0027\n    该函数实现以日为单位切分训练数据和测试数据\n    \u0027\u0027\u0027\n    # train \u003d dataset[23:35063]\n    # test \u003d dataset[35063:-2]\n    train \u003d dataset[1702:30982]\n    test \u003d dataset[30982:36718]\n    train \u003d np.array(np.split(train, len(train)/24)) # 将数据划分为按天为单位的数据\n    test \u003d np.array(np.split(test, len(test)/24))\n    # train.shape\n    # train.head(10)\n    # test.tail(10)\n    return train, test\n\ndef evaluate_forecasts(actual, predicted):\n    \u0027\u0027\u0027\n    该函数实现根据预期值评估一个或多个周预测损失\n    思路：统计所有单日预测的 RMSE\n    \u0027\u0027\u0027\n    scores \u003d list()\n    MAE \u003d list()\n    for i in range(actual.shape[1]):\n        mse \u003d skm.mean_squared_error(actual[:, i], predicted[:, i])\n        rmse \u003d math.sqrt(mse)\n        scores.append(rmse)\n        x \u003d skm.mean_absolute_error(actual[:, i], predicted[:, i])\n        MAE.append(x)\n    \n    s \u003d 0 # 计算总的 RMSE\n    for row in range(actual.shape[0]):\n        for col in range(actual.shape[1]):\n            s +\u003d (actual[row, col] - predicted[row, col]) ** 2\n    score \u003d math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n    print(\u0027actual.shape[0]:{}, actual.shape[1]:{}\u0027.format(actual.shape[0], actual.shape[1]))\n    return score, scores,MAE\n\ndef summarize_scores(name, score, scores,MAE):\n    s_scores \u003d \u0027, \u0027.join([\u0027%.1f\u0027 % s for s in scores])\n    print(\u0027%s: [%.3f] %s\\n\u0027 % (name, score, s_scores))\n    print(MAE)\n    \ndef sliding_window(train, sw_width\u003d24, n_out\u003d24, in_start\u003d0):\n    \u0027\u0027\u0027\n    该函数实现窗口宽度为7、滑动步长为1的滑动窗口截取序列数据\n    \u0027\u0027\u0027\n    data \u003d train.reshape((train.shape[0] * train.shape[1], train.shape[2])) # 将以周为单位的样本展平为以天为单位的序列\n    X, y \u003d [], []\n    \n    for _ in range(len(data)):\n        in_end \u003d in_start + sw_width\n        out_end \u003d in_end + n_out\n        \n        # 保证截取样本完整，最大元素索引不超过原序列索引，则截取数据；否则丢弃该样本\n        if out_end \u003c len(data):\n            # 训练数据以滑动步长1截取\n            train_seq \u003d data[in_start:in_end, 0]\n            train_seq \u003d train_seq.reshape((len(train_seq), 1))\n            X.append(train_seq)\n            y.append(data[in_end:out_end, 0])\n        in_start +\u003d 1\n        \n    return np.array(X), np.array(y)\n\ndef conv_lstm_model(train, sw_width, n_steps, n_length, in_start\u003d0, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4):\n    \u0027\u0027\u0027\n    该函数定义 Encoder-Decoder LSTM 模型\n    \u0027\u0027\u0027\n    train_x, train_y \u003d sliding_window(train, sw_width, in_start\u003d0)\n    n_timesteps, n_features, n_outputs \u003d train_x.shape[1], train_x.shape[2], train_y.shape[1]\n    \n    train_x \u003d train_x.reshape((train_x.shape[0], n_steps, 1, n_length, n_features))\n    train_y \u003d train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n    \n    model \u003d Sequential()\n    model.add(ConvLSTM2D(filters\u003d64, kernel_size\u003d(1,3), activation\u003d\u0027relu\u0027,\n                         input_shape\u003d(n_steps, 1, n_length, n_features)))\n    model.add(Flatten())\n    model.add(RepeatVector(n_outputs))\n    model.add(LSTM(200, activation\u003d\u0027relu\u0027, return_sequences\u003dTrue))\n    model.add(TimeDistributed(Dense(100, activation\u003d\u0027relu\u0027)))\n    model.add(TimeDistributed(Dense(1)))\n    \n    model.compile(loss\u003d\u0027mse\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n    print(model.summary())\n    \n    model.fit(train_x, train_y,\n              epochs\u003depochs_num, batch_size\u003dbatch_size_set, verbose\u003dverbose_set)\n    return model\n\ndef forecast(model, pred_seq, sw_width, n_length, n_steps):\n    \u0027\u0027\u0027\n    该函数实现对输入数据的预测\n    \u0027\u0027\u0027\n    data \u003d np.array(pred_seq)\n    data \u003d data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n    \n    input_x \u003d data[-sw_width:, 0] # 获取输入数据的最后一周的数据\n    input_x \u003d input_x.reshape((1, n_steps, 1, n_length, 1))\n    \n    yhat \u003d model.predict(input_x, verbose\u003d0) # 预测下周数据\n    yhat \u003d yhat[0] # 获取预测向量\n    return yhat\n\ndef evaluate_model(model, train, test, sd_width, n_length, n_steps):\n    \u0027\u0027\u0027\n    该函数实现模型评估\n    \u0027\u0027\u0027\n    history_fore \u003d [x for x in train]\n    predictions \u003d list() # 用于保存每周的前向验证结果；\n    for i in range(len(test)):\n        yhat_sequence \u003d forecast(model, history_fore, sd_width, n_length, n_steps) # 预测下周的数据\n        predictions.append(yhat_sequence) # 保存预测结果\n        history_fore.append(test[i, :]) # 得到真实的观察结果并添加到历史中以预测下周\n    \n    predictions \u003d np.array(predictions) # 评估一周中每天的预测结果\n    score, scores,MAE \u003d evaluate_forecasts(test[:, :, 0], predictions)\n    return score, scores,MAE\n\ndef model_plot(score, scores, days, name):\n    \u0027\u0027\u0027\n    该函数实现绘制RMSE曲线图\n    \u0027\u0027\u0027\n    plt.figure(figsize\u003d(8,6), dpi\u003d150)\n    plt.plot(days, scores, marker\u003d\u0027o\u0027, label\u003dname)\n    plt.grid(linestyle\u003d\u0027--\u0027, alpha\u003d0.5)\n    plt.ylabel(r\u0027$RMSE$\u0027, size\u003d15)\n    plt.title(\u0027Conv-LSTM 模型预测结果\u0027,  size\u003d18)\n    plt.legend()\n    plt.show()\n    \ndef main_run(dataset, sw_width, days, name, in_start, verbose, epochs, batch_size, n_steps, n_length):\n    \u0027\u0027\u0027\n    主函数：数据处理、模型训练流程\n    \u0027\u0027\u0027\n    # 划分训练集和测试集\n    train, test \u003d split_dataset(dataset.values)\n    # 训练模型\n    model \u003d conv_lstm_model(train, sw_width,  n_steps, n_length, in_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n    # 计算RMSE\n    score, scores \u003d evaluate_model(model, train, test, sw_width, n_length, n_steps)\n    # 打印分数\n    summarize_scores(name, score, scores)\n    # 绘图\n    model_plot(score, scores, days, name)\n        \n    \nif __name__ \u003d\u003d \u0027__main__\u0027:\n    \n    dataset \u003d pd.read_csv(\u0027./LD_MT200_hour.csv\u0027, header\u003d0,\n                      low_memory\u003dFalse, infer_datetime_format\u003dTrue, engine\u003d\u0027c\u0027, index_col\u003d[\u0027date\u0027])\n    values \u003d dataset.values.astype(\u0027float32\u0027)\n    dataset[\u0027ELE_SUM\u0027] \u003d (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n    \n    train, test \u003d split_dataset(dataset.values)\n    \n    \n    name \u003d \u0027Conv-LSTM\u0027\n    \n    # 定义序列的数量和长度\n    \u0027\u0027\u0027\n    n_steps：子序列划分的数量，本例为2，将14天的数据划分为两个7的子序列；\n    n_length：子序列每行的元素数，即列数。\n    \u0027\u0027\u0027\n    n_steps, n_length \u003d 2, 7\n    \n    sliding_window_width\u003d n_length * n_steps\n    input_sequence_start\u003d0\n    \n    epochs_num\u003d20\n    batch_size_set\u003d16\n    verbose_set\u003d0\n    \n    model \u003d conv_lstm_model(train, sliding_window_width, n_steps, n_length, input_sequence_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n\n    test.shape\n    score, scores,MAE \u003d evaluate_model(model, train, test, sliding_window_width, n_length, n_steps)\n    \n    \n    \n    # db \u003d pymysql.connect(host\u003d\"localhost\", user\u003d\"root\", password\u003d\"LQW1107@python\", database\u003d\"modeldata\",charset\u003d\"utf8\")\n    # cursor \u003d db.cursor()\n    # sql \u003d \"insert into modelinfo values \u003d (\" + name + \u0027,\u0027 + score + \u0027,\u0027 +MAE \n    # cursor.execute(sql)\n    \n    summarize_scores(name, score, scores,MAE)\n    # main_run(dataset, sliding_window_width, days, name, input_sequence_start,\n    #          verbose_set, epochs_num, batch_size_set, n_steps, n_length)\n    ",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}