{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "a\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 设置中文显示\nplt.rcParams[\u0027font.sans-serif\u0027] \u003d [\u0027Microsoft JhengHei\u0027]\nplt.rcParams[\u0027axes.unicode_minus\u0027] \u003d False\n\nimport math\nimport sklearn.metrics as skm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense,Conv1D,MaxPooling1D,Flatten,RepeatVector\nfrom tensorflow.keras.layers import RepeatVector, TimeDistributed\n\n\nprint(\u0027a\u0027)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n conv1d_2 (Conv1D)           (None, 22, 64)            256       \n                                                                 \n conv1d_3 (Conv1D)           (None, 20, 64)            12352     \n                                                                 \n max_pooling1d_1 (MaxPooling  (None, 10, 64)           0         \n 1D)                                                             \n                                                                 \n flatten_1 (Flatten)         (None, 640)               0         \n                                                                 \n repeat_vector_1 (RepeatVect  (None, 24, 640)          0         \n or)                                                             \n                                                                 \n lstm_1 (LSTM)               (None, 24, 200)           672800    \n                                                                 \n time_distributed_2 (TimeDis  (None, 24, 100)          20100     \n tributed)                                                       \n                                                                 \n time_distributed_3 (TimeDis  (None, 24, 1)            101       \n tributed)                                                       \n                                                                 \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 705,609\nTrainable params: 705,609\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
            "actual.shape[0]:239, actual.shape[1]:24\nen-de-lstm: [256.610] 81.4, 93.7, 137.0, 138.4, 149.3, 170.9, 226.7, 286.9, 305.9, 281.7, 277.4, 283.3, 280.1, 286.3, 294.6, 289.3, 301.2, 312.2, 303.3, 298.0, 299.4, 305.7, 270.2, 236.0\n\n[64.56245147832767, 70.96519821358525, 96.4113590767194, 105.00050922218227, 111.11174949741762, 128.73379886898536, 178.84039945083683, 230.91315744312237, 245.2996412460774, 216.17701165745947, 211.44758740030073, 216.69744438905596, 209.71024389546287, 214.2548491027066, 225.89556501699792, 220.72025468259676, 235.14479377778505, 243.90884667560147, 233.80863563186455, 228.97390861990064, 236.1788621208159, 241.9548462424817, 211.2028226333682, 184.08871396116632]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def split_dataset(data):\n    \u0027\u0027\u0027\n    该函数实现以日为单位切分训练数据和测试数据\n    \u0027\u0027\u0027\n    # train \u003d dataset[23:35063]\n    # test \u003d dataset[35063:-2]\n    train \u003d dataset[1702:30982]\n    test \u003d dataset[30982:36718]\n    train \u003d np.array(np.split(train, len(train)/24)) # 将数据划分为按天为单位的数据\n    test \u003d np.array(np.split(test, len(test)/24))\n    # train.shape\n    # train.head(10)\n    # test.tail(10)\n    return train, test\n\n\ndef evaluate_forecasts(actual, predicted):\n    \u0027\u0027\u0027\n    该函数实现根据预期值评估一个或多个周预测损失\n    思路：统计所有单日预测的 RMSE\n    \u0027\u0027\u0027\n    scores \u003d list()\n    MAE \u003d list()\n    for i in range(actual.shape[1]):\n        mse \u003d skm.mean_squared_error(actual[:, i], predicted[:, i])\n        rmse \u003d math.sqrt(mse)\n        scores.append(rmse)\n        x \u003d skm.mean_absolute_error(actual[:, i], predicted[:, i])\n        MAE.append(x)\n        \n    \n    s \u003d 0 # 计算总的 RMSE\n    for row in range(actual.shape[0]):\n        for col in range(actual.shape[1]):\n            s +\u003d (actual[row, col] - predicted[row, col]) ** 2\n    score \u003d math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n    print(\u0027actual.shape[0]:{}, actual.shape[1]:{}\u0027.format(actual.shape[0], actual.shape[1]))\n    return score, scores,MAE\n\ndef summarize_scores(name, score, scores,MAE):\n    s_scores \u003d \u0027, \u0027.join([\u0027%.1f\u0027 % s for s in scores])\n    print(\u0027%s: [%.3f] %s\\n\u0027 % (name, score, s_scores))\n    print(MAE)\ndef sliding_window(train, sw_width\u003d24, n_out\u003d24, in_start\u003d0):\n    \u0027\u0027\u0027\n    该函数实现窗口宽度为7、滑动步长为1的滑动窗口截取序列数据\n    \u0027\u0027\u0027\n    data \u003d train.reshape((train.shape[0] * train.shape[1], train.shape[2])) # 将以周为单位的样本展平为以天为单位的序列\n    X, y \u003d [], []\n    \n    for _ in range(len(data)):\n        in_end \u003d in_start + sw_width\n        out_end \u003d in_end + n_out\n        \n        # 保证截取样本完整，最大元素索引不超过原序列索引，则截取数据；否则丢弃该样本\n        if out_end \u003c len(data):\n            # 训练数据以滑动步长1截取\n            train_seq \u003d data[in_start:in_end, 0]\n            train_seq \u003d train_seq.reshape((len(train_seq), 1))\n            X.append(train_seq)\n            y.append(data[in_end:out_end, 0])\n        in_start +\u003d 1\n        \n    return np.array(X), np.array(y)\n    \ndef cnn_lstm_model(train, sw_width, in_start\u003d0, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4):\n    \u0027\u0027\u0027\n    该函数定义 Encoder-Decoder LSTM 模型\n    \u0027\u0027\u0027\n    train_x, train_y \u003d sliding_window(train, sw_width, in_start\u003d0)\n    \n    n_timesteps, n_features, n_outputs \u003d train_x.shape[1], train_x.shape[2], train_y.shape[1]\n    \n    train_y \u003d train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n    \n    model \u003d Sequential()\n    model.add(Conv1D(filters\u003d64, kernel_size\u003d3, activation\u003d\u0027relu\u0027,\n                     input_shape\u003d(n_timesteps,n_features)))\n    model.add(Conv1D(filters\u003d64, kernel_size\u003d3, activation\u003d\u0027relu\u0027))\n    model.add(MaxPooling1D(pool_size\u003d2))\n    model.add(Flatten())\n    model.add(RepeatVector(n_outputs))\n    model.add(LSTM(200, activation\u003d\u0027relu\u0027, return_sequences\u003dTrue))\n    model.add(TimeDistributed(Dense(100, activation\u003d\u0027relu\u0027)))\n    model.add(TimeDistributed(Dense(1)))\n    \n    model.compile(loss\u003d\u0027mse\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n    print(model.summary())\n    \n    model.fit(train_x, train_y,\n              epochs\u003depochs_num, batch_size\u003dbatch_size_set, verbose\u003dverbose_set)\n    return model\n\ndef forecast(model, pred_seq, sw_width):\n    \u0027\u0027\u0027\n    该函数实现对输入数据的预测\n    \u0027\u0027\u0027\n    data \u003d np.array(pred_seq)\n    data \u003d data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n    \n    input_x \u003d data[-sw_width:, 0] # 获取输入数据的最后一周的数据\n    input_x \u003d input_x.reshape((1, len(input_x), 1)) # 重塑形状[1, sw_width, 1]\n    \n    yhat \u003d model.predict(input_x, verbose\u003d0) # 预测下周数据\n    yhat \u003d yhat[0] # 获取预测向量\n    return yhat\n\ndef evaluate_model(model, train, test, sd_width):\n    \u0027\u0027\u0027\n    该函数实现模型评估\n    \u0027\u0027\u0027\n    history_fore \u003d [x for x in train]\n    predictions \u003d list() # 用于保存每周的前向验证结果；\n    for i in range(len(test)):\n        yhat_sequence \u003d forecast(model, history_fore, sd_width) # 预测下周的数据\n        predictions.append(yhat_sequence) # 保存预测结果\n        history_fore.append(test[i, :]) # 得到真实的观察结果并添加到历史中以预测下周\n    \n    predictions \u003d np.array(predictions) # 评估一周中每天的预测结果\n    score, scores ,MAE\u003d evaluate_forecasts(test[:, :, 0], predictions)\n    return score, scores, MAE\n\ndef model_plot(score, scores, days, name):\n    \u0027\u0027\u0027\n    该函数实现绘制RMSE曲线图\n    \u0027\u0027\u0027\n    plt.figure(figsize\u003d(8,6), dpi\u003d150)\n    plt.plot(days, scores, marker\u003d\u0027o\u0027, label\u003dname)\n    plt.grid(linestyle\u003d\u0027--\u0027, alpha\u003d0.5)\n    plt.ylabel(r\u0027$RMSE$\u0027, size\u003d15)\n    plt.title(\u0027CNN-LSTM 模型预测结果\u0027,  size\u003d18)\n    plt.legend()\n    plt.show()\n    \n# def main_run(dataset, sw_width, days, name, in_start, verbose, epochs, batch_size):\n#     \u0027\u0027\u0027\n#     主函数：数据处理、模型训练流程\n#     \u0027\u0027\u0027\n#     # 划分训练集和测试集\n#     train, test \u003d split_dataset(dataset.values)\n#     # 训练模型\n#     model \u003d cnn_lstm_model(train, sw_width, in_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n#     # 计算RMSE\n#     score, scores \u003d evaluate_model(model, train, test, sw_width)\n#     # 打印分数\n#     summarize_scores(name, score, scores)\n#     # 绘图\n#     model_plot(score, scores, days, name)\n#     \n#     print(\u0027------头发不够，帽子来凑-----\u0027)\n#     \n    \nif __name__ \u003d\u003d \u0027__main__\u0027:\n    \n    dataset \u003d pd.read_csv(\u0027./LD_MT200_hour.csv\u0027, header\u003d0,\n                      low_memory\u003dFalse, infer_datetime_format\u003dTrue, engine\u003d\u0027c\u0027, index_col\u003d[\u0027date\u0027])\n    values \u003d dataset.values.astype(\u0027float32\u0027)\n    dataset[\u0027ELE_SUM\u0027] \u003d (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n    \n    train, test \u003d split_dataset(dataset.values)\n    \n    # hours \u003d [\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00272\u0027,\u00274\u0027,\u00275\u0027,\u00276\u0027,\u00277\u0027,\u00278\u0027,\u00279\u0027,\u002710\u0027,\u002711\u0027,\u002712\u0027,\u002713\u0027,\u002714\u0027,\u002715\u0027,\u002716\u0027,\u002717\u0027,\u002718\u0027,\u002719\u0027,\u002720\u0027,\u002721\u0027,\u002722\u0027,\u002723\u0027]\n    name \u003d \u0027en-de-lstm\u0027\n    \n    sliding_window_width\u003d 24\n    input_sequence_start\u003d0\n    \n    epochs_num\u003d20\n    batch_size_set\u003d16\n    verbose_set\u003d0\n    \n    model \u003d cnn_lstm_model(train, sliding_window_width, input_sequence_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n    test.shape\n    score, scores, MAE\u003d evaluate_model(model, train, test, sliding_window_width)\n    \n    # db \u003d pymysql.connect(host\u003d\"localhost\", user\u003d\"root\", password\u003d\"LQW1107@python\", database\u003d\"modeldata\",charset\u003d\"utf8\")\n    # cursor \u003d db.cursor()\n    # sql \u003d \"insert into modelinfo values \u003d (\" + name + \u0027,\u0027 + score + \u0027,\u0027 +MAE \n    # cursor.execute(sql)\n    \n    summarize_scores(name, score, scores,MAE)\n    # main_run(dataset, sliding_window_width, days, name, input_sequence_start,\n    #          verbose_set, epochs_num, batch_size_set)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}