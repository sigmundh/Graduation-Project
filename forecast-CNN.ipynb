{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport math\n\nimport sklearn.metrics as skm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import Conv1D,MaxPooling1D\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n conv1d (Conv1D)             (None, 22, 16)            64        \n                                                                 \n max_pooling1d (MaxPooling1D  (None, 11, 16)           0         \n )                                                               \n                                                                 \n flatten (Flatten)           (None, 176)               0         \n                                                                 \n dense (Dense)               (None, 10)                1770      \n                                                                 \n dense_1 (Dense)             (None, 24)                264       \n                                                                 \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 2,098\nTrainable params: 2,098\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
            "actual.shape[0]:239, actual.shape[1]:24\ncnn: [372.996] 117.4, 106.0, 224.8, 293.1, 353.3, 359.4, 334.2, 379.8, 400.9, 363.6, 325.4, 306.5, 298.4, 308.4, 326.7, 353.5, 394.5, 433.9, 479.1, 532.7, 557.5, 537.6, 441.6, 327.1\n\n[97.67888152948483, 85.36684733753923, 186.92365600075183, 254.38565689150758, 301.68648155563545, 292.0280327577471, 252.1387995636114, 297.7171630859375, 322.223088348261, 285.82009900464175, 248.80628411839697, 226.13321395299425, 220.37249321718096, 231.89738943187763, 250.11694744541057, 270.6540190245816, 298.8168832946522, 325.9547890379838, 377.1896257600026, 450.6637591118593, 483.5047132420241, 466.0284771141148, 373.0573137993593, 261.14889820050996]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def split_dataset(data):\n    \u0027\u0027\u0027\n    该函数实现以日为单位切分训练数据和测试数据\n    \u0027\u0027\u0027\n    # train \u003d dataset[23:35063]\n    # test \u003d dataset[35063:-2]\n    train \u003d dataset[1702:30982]\n    test \u003d dataset[30982:36718]\n    train \u003d np.array(np.split(train, len(train)/24)) # 将数据划分为按天为单位的数据\n    test \u003d np.array(np.split(test, len(test)/24))\n    # train.shape\n    # train.head(10)\n    # test.tail(10)\n    return train, test\n\ndef evaluate_forecasts(actual, predicted):\n    \n    scores \u003d list()\n    MAE \u003d list()\n    for i in range(actual.shape[1]):\n        mse \u003d skm.mean_squared_error(actual[:, i], predicted[:, i])\n        rmse \u003d math.sqrt(mse)\n        scores.append(rmse)\n        x \u003d skm.mean_absolute_error(actual[:, i], predicted[:, i])\n        MAE.append(x)\n    \n    s \u003d 0 \n    for row in range(actual.shape[0]):\n        for col in range(actual.shape[1]):\n            s +\u003d (actual[row, col] - predicted[row, col]) ** 2\n    score \u003d math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n    print(\u0027actual.shape[0]:{}, actual.shape[1]:{}\u0027.format(actual.shape[0], actual.shape[1]))\n    Y \u003d MAE/24\n    \n    \n    return score, scores, MAE\n\ndef summarize_scores(name, score, scores, MAE):\n    s_scores \u003d \u0027, \u0027.join([\u0027%.1f\u0027 % s for s in scores])\n    print(\u0027%s: [%.3f] %s\\n\u0027 % (name, score, s_scores))\n    print(MAE)\n\n\n\n\n\ndef sliding_window(train, sw_width\u003d24, n_out\u003d24, in_start\u003d0):\n   \n    data \u003d train.reshape((train.shape[0] * train.shape[1], train.shape[2])) \n    X, y \u003d [], []\n    \n    for _ in range(len(data)):\n        in_end \u003d in_start + sw_width\n        out_end \u003d in_end + n_out\n         \n        if out_end \u003c len(data):\n            train_seq \u003d data[in_start:in_end, 0]\n            train_seq \u003d train_seq.reshape((len(train_seq), 1))\n            X.append(train_seq)\n            y.append(data[in_end:out_end, 0])\n        in_start +\u003d 1\n    return np.array(X), np.array(y)\n\ndef cnn_model(train, sw_width, in_start\u003d0, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4):\n    \n    train_x, train_y \u003d sliding_window(train, sw_width, in_start\u003d0)\n    \n    n_timesteps, n_features, n_outputs \u003d train_x.shape[1], train_x.shape[2], train_y.shape[1]\n    \n    model \u003d Sequential()\n    model.add(Conv1D(filters\u003d16, kernel_size\u003d3, activation\u003d\u0027relu\u0027, \n                     input_shape\u003d(n_timesteps, n_features)))\n    \n    model.add(MaxPooling1D(pool_size\u003d2))\n    model.add(Flatten())\n    model.add(Dense(10, activation\u003d\u0027relu\u0027))\n    \n    \n    model.add(Dense(units\u003dn_outputs))\n    \n    model.compile(loss\u003d\u0027mse\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n    print(model.summary())\n    \n    model.fit(train_x, train_y,epochs\u003depochs_num, batch_size\u003dbatch_size_set, verbose\u003dverbose_set)\n    return model\n\ndef forecast(model, pred_seq, sw_width):\n    \u0027\u0027\u0027\n    该函数实现对输入数据的预测\n    \u0027\u0027\u0027\n    data \u003d np.array(pred_seq)\n    data \u003d data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n    \n    input_x \u003d data[-sw_width:, 0] # 获取输入数据的最后一周的数据\n    input_x \u003d input_x.reshape((1, len(input_x), 1)) # 重塑形状[1, sw_width, 1]\n    \n    yhat \u003d model.predict(input_x, verbose\u003d0) # 预测下周数据\n    yhat \u003d yhat[0] # 获取预测向量\n    return yhat\n\ndef evaluate_model(model, train, test, sd_width):\n    \u0027\u0027\u0027\n   print scoro\n    \u0027\u0027\u0027\n    history_fore \u003d [x for x in train]\n    predictions \u003d list() # 用于保存每周的前向验证结果；\n    for i in range(len(test)):\n        yhat_sequence \u003d forecast(model, history_fore, sd_width) # 预测下周期的数据\n        predictions.append(yhat_sequence) # 保存结果\n        history_fore.append(test[i, :]) # 添加到历史中以预测下周\n        \n    \n    predictions \u003d np.array(predictions) \n    score, scores, MAE \u003d evaluate_forecasts(test[:, :, 0], predictions)\n    return score, scores, MAE\n    \ndef model_plot(score, scores, hours, name):\n    \u0027\u0027\u0027\n    该函数实现绘制RMSE曲线图\n    \u0027\u0027\u0027\n    plt.figure(figsize\u003d(8,6), dpi\u003d150)\n    plt.plot(hours, scores, marker\u003d\u0027o\u0027, label\u003dname)\n    plt.grid(linestyle\u003d\u0027--\u0027, alpha\u003d0.5)\n    plt.ylabel(r\u0027$RMSE$\u0027, size\u003d15)\n    plt.title(\u0027CNN 模型预测结果\u0027,  size\u003d18)\n    plt.legend()\n    plt.show()\n    \n    \n    \n    \n    \n    \n    \n# def main_run(dataset, sw_width, hours, name, in_start, verbose, epochs, batch_size):\n#     \n#    \n#     \n#     \n#     train, test \u003d split_dataset(dataset.values)\n#     model \u003d cnn_model(train, sw_width, in_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n#     RMSE\n#     score, scores \u003d evaluate_model(model, train, test, sw_width)\n#     summarize_scores(name, score, scores) \n#     model_plot(score, scores, hours, name)\n#    \n\nif __name__ \u003d\u003d \u0027__main__\u0027:\n    \n    dataset \u003d pd.read_csv(\u0027./LD_MT200_hour.csv\u0027, header\u003d0,\n                      low_memory\u003dFalse, infer_datetime_format\u003dTrue, engine\u003d\u0027c\u0027, index_col\u003d[\u0027date\u0027])\n    values \u003d dataset.values.astype(\u0027float32\u0027)\n    dataset[\u0027ELE_SUM\u0027] \u003d (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n\n    dataset.shape\n    dataset.head(10)\n    dataset.shape\n    dataset.head(10)\n\n    train, test \u003d split_dataset(dataset.values)\n\n    # hours \u003d [\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00272\u0027,\u00274\u0027,\u00275\u0027,\u00276\u0027,\u00277\u0027,\u00278\u0027,\u00279\u0027,\u002710\u0027,\u002711\u0027,\u002712\u0027,\u002713\u0027,\u002714\u0027,\u002715\u0027,\u002716\u0027,\u002717\u0027,\u002718\u0027,\u002719\u0027,\u002720\u0027,\u002721\u0027,\u002722\u0027,\u002723\u0027]\n    name \u003d \u0027cnn\u0027\n\n    sliding_window_width\u003d24\n    input_sequence_start\u003d0\n\n\n\n    epochs_num\u003d20\n    batch_size_set\u003d4\n    verbose_set\u003d0\n    model \u003d cnn_model(train, sliding_window_width, input_sequence_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n    test.shape\n    score, scores, MAE \u003d evaluate_model(model, train, test, sliding_window_width)\n    \n    # db \u003d pymysql.connect(host\u003d\"localhost\", user\u003d\"root\", password\u003d\"LQW1107@python\", database\u003d\"modeldata\",charset\u003d\"utf8\")\n    # cursor \u003d db.cursor()\n    # sql \u003d \"insert into modelinfo values \u003d (\" + name + \u0027,\u0027 + score + \u0027,\u0027 +MAE \n    # cursor.execute(sql)\n    \n    summarize_scores(name, score, scores, MAE)\n    # \n    # main_run(dataset, sliding_window_width, hours, name, input_sequence_start,\n    #          verbose_set, epochs_num, batch_size_set)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "cnn: [351.587] 129.5, 221.5, 311.7, 359.3, 398.5, 393.3, 348.8, 357.6, 368.5, 340.3, 313.1, 306.3, 309.6, 319.5, 335.4, 356.3, 373.9, 378.6, 384.7, 414.9, 448.1, 446.5, 375.0, 294.8\n\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "# summarize_scores(name, score, scores,acc)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}