{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sklearn.metrics as skm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_dataset(data):\n",
    "    '''\n",
    "    该函数实现以日为单位切分训练数据和测试数据\n",
    "    '''\n",
    "    train = dataset[23:35063]\n",
    "    test = dataset[35064:-2]\n",
    "    train = np.array(np.split(train, len(train)/24)) # 将数据划分为按天为单位的数据\n",
    "    test = np.array(np.split(test, len(test)/24))\n",
    "    # train.shape\n",
    "    # train.head(10)\n",
    "    # test.tail(10)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 22, 16)            64        \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 11, 16)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 176)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1770      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 24)                264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,098\n",
      "Trainable params: 2,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def evaluate_forecasts(actual, predicted):\n",
    "    '''\n",
    "    该函数实现根据预期值评估一个或多个周预测损失\n",
    "    思路：统计所有单日预测的 RMSE\n",
    "    '''\n",
    "    scores = list()\n",
    "    for i in range(actual.shape[1]):\n",
    "        mse = skm.mean_squared_error(actual[:, i], predicted[:, i])\n",
    "        rmse = math.sqrt(mse)\n",
    "        scores.append(rmse)\n",
    "    \n",
    "    s = 0 # 计算总的 RMSE\n",
    "    for row in range(actual.shape[0]):\n",
    "        for col in range(actual.shape[1]):\n",
    "            s += (actual[row, col] - predicted[row, col]) ** 2\n",
    "    score = math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n",
    "    print('actual.shape[0]:{}, actual.shape[1]:{}'.format(actual.shape[0], actual.shape[1]))\n",
    "    return score, scores\n",
    "\n",
    "def summarize_scores(name, score, scores):\n",
    "    s_scores = ', '.join(['%.1f' % s for s in scores])\n",
    "    print('%s: [%.3f] %s\\n' % (name, score, s_scores))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sliding_window(train, sw_width=24, n_out=24, in_start=0):\n",
    "    '''\n",
    "    该函数实现窗口宽度为7、滑动步长为1的滑动窗口截取序列数据\n",
    "    '''\n",
    "    data = train.reshape((train.shape[0] * train.shape[1], train.shape[2])) # 将以周为单位的样本展平为以天为单位的序列\n",
    "    X, y = [], []\n",
    "    \n",
    "    for _ in range(len(data)):\n",
    "        in_end = in_start + sw_width\n",
    "        out_end = in_end + n_out\n",
    "        \n",
    "        # 保证截取样本完整，最大元素索引不超过原序列索引，则截取数据；否则丢弃该样本\n",
    "        if out_end < len(data):\n",
    "            # 训练数据以滑动步长1截取\n",
    "            train_seq = data[in_start:in_end, 0]\n",
    "            train_seq = train_seq.reshape((len(train_seq), 1))\n",
    "            X.append(train_seq)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        in_start += 1\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def cnn_model(train, sw_width, in_start=0, verbose_set=0, epochs_num=20, batch_size_set=4):\n",
    "    '''\n",
    "    该函数定义 1D CNN 模型\n",
    "    '''\n",
    "    train_x, train_y = sliding_window(train, sw_width, in_start=0)\n",
    "    \n",
    "    n_timesteps, n_features, n_outputs = train_x.shape[1], train_x.shape[2], train_y.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=16, kernel_size=3, activation='relu', \n",
    "                     input_shape=(n_timesteps, n_features)))\n",
    "    \n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(units=n_outputs))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    \n",
    "    model.fit(train_x, train_y,epochs=epochs_num, batch_size=batch_size_set, verbose=verbose_set)\n",
    "    return model\n",
    "\n",
    "def forecast(model, pred_seq, sw_width):\n",
    "    '''\n",
    "    该函数实现对输入数据的预测\n",
    "    '''\n",
    "    data = np.array(pred_seq)\n",
    "    data = data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n",
    "    \n",
    "    input_x = data[-sw_width:, 0] # 获取输入数据的最后一周的数据\n",
    "    input_x = input_x.reshape((1, len(input_x), 1)) # 重塑形状[1, sw_width, 1]\n",
    "    \n",
    "    yhat = model.predict(input_x, verbose=0) # 预测下周数据\n",
    "    yhat = yhat[0] # 获取预测向量\n",
    "    return yhat\n",
    "\n",
    "def evaluate_model(model, train, test, sd_width):\n",
    "    '''\n",
    "   print scoro\n",
    "    '''\n",
    "    history_fore = [x for x in train]\n",
    "    predictions = list() # 用于保存每周的前向验证结果；\n",
    "    for i in range(len(test)):\n",
    "        yhat_sequence = forecast(model, history_fore, sd_width) # 预测下周期的数据\n",
    "        predictions.append(yhat_sequence) # 保存结果\n",
    "        history_fore.append(test[i,:]) # 添加到历史中以预测下周\n",
    "        \n",
    "    \n",
    "    predictions = np.array(predictions) \n",
    "    score, scores = evaluate_forecasts(test[:, :, 0], predictions)\n",
    "    return score, scores\n",
    "\n",
    "def model_plot(score, scores, hours, name):\n",
    "    '''\n",
    "    该函数实现绘制RMSE曲线图\n",
    "    '''\n",
    "    plt.figure(figsize=(8,6), dpi=150)\n",
    "    plt.plot(hours, scores, marker='o', label=name)\n",
    "    plt.grid(linestyle='--', alpha=0.5)\n",
    "    plt.ylabel(r'$RMSE$', size=15)\n",
    "    plt.title('CNN 模型预测结果',  size=18)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# def main_run(dataset, sw_width, hours, name, in_start, verbose, epochs, batch_size):\n",
    "#     \n",
    "#    \n",
    "#     \n",
    "#     \n",
    "#     train, test = split_dataset(dataset.values)\n",
    "#     model = cnn_model(train, sw_width, in_start, verbose_set=0, epochs_num=20, batch_size_set=4)\n",
    "#     RMSE\n",
    "#     score, scores = evaluate_model(model, train, test, sw_width)\n",
    "#     summarize_scores(name, score, scores) \n",
    "#     model_plot(score, scores, hours, name)\n",
    "#         \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    dataset = pd.read_csv('./LD_MT200_hour.csv', header=0,\n",
    "                      low_memory=False, infer_datetime_format=True, engine='c', index_col=['date'])\n",
    "    values = dataset.values.astype('float32')\n",
    "    dataset['ELE_SUM'] = (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n",
    "\n",
    "    dataset.shape\n",
    "    dataset.head(10)\n",
    "    dataset.shape\n",
    "    dataset.head(10)\n",
    "\n",
    "    train, test = split_dataset(dataset.values)\n",
    "\n",
    "    # hours = ['0','1','2','2','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
    "    name = 'cnn'\n",
    "\n",
    "    sliding_window_width=24\n",
    "    input_sequence_start=0\n",
    "\n",
    "\n",
    "\n",
    "    epochs_num=20\n",
    "    batch_size_set=4\n",
    "    verbose_set=0\n",
    "    model = cnn_model(train, sliding_window_width, input_sequence_start, verbose_set=0, epochs_num=20, batch_size_set=4)\n",
    "    test.shape\n",
    "#     score, scores = evaluate_model(model, train, test, sliding_window_width)\n",
    "\n",
    "    # \n",
    "    # main_run(dataset, sliding_window_width, hours, name, input_sequence_start,\n",
    "    #          verbose_set, epochs_num, batch_size_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset = pd.read_csv('./LD_MT200_hour.csv', header=0,\n",
    "                      low_memory=False, infer_datetime_format=True, engine='c', index_col=['date'])\n",
    "values = dataset.values.astype('float32')\n",
    "daily_groups = dataset.resample('D')\n",
    "daily_groups.sum()\n",
    "\n",
    "daily_data = daily_groups.sum()\n",
    "# dataset['ELE_SUM'] = (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n",
    "# dataset1=dataset['ELE_SUM']\n",
    "daily_data.shape\n",
    "daily_data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
