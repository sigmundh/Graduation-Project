{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# 设置中文显示\nplt.rcParams[\u0027font.sans-serif\u0027] \u003d [\u0027Microsoft JhengHei\u0027]\nplt.rcParams[\u0027axes.unicode_minus\u0027] \u003d False\n\nimport math\nimport sklearn.metrics as skm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense,RepeatVector,TimeDistributed\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n lstm (LSTM)                 (None, 200)               161600    \n                                                                 \n repeat_vector (RepeatVector  (None, 24, 200)          0         \n )                                                               \n                                                                 \n lstm_1 (LSTM)               (None, 24, 200)           320800    \n                                                                 \n time_distributed (TimeDistr  (None, 24, 100)          20100     \n ibuted)                                                         \n                                                                 \n time_distributed_1 (TimeDis  (None, 24, 1)            101       \n tributed)                                                       \n                                                                 \n\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\nTotal params: 502,601\nTrainable params: 502,601\nNon-trainable params: 0\n_________________________________________________________________\nNone\n",
            "actual.shape[0]:239, actual.shape[1]:24\nen-de-lstm: [281.713] 64.2, 122.9, 161.9, 181.5, 220.8, 261.0, 257.8, 301.9, 332.4, 301.1, 305.4, 316.3, 314.2, 313.3, 318.7, 335.8, 335.2, 318.3, 314.5, 323.5, 318.5, 308.7, 269.4, 244.0\n\n[50.12358521018567, 105.75010061862578, 125.35448401542887, 153.1696935677628, 189.174649928903, 224.36341864294587, 204.65237133074007, 232.555034813023, 255.4478984497581, 223.8881309860421, 223.83619134495947, 233.26404319348197, 232.69476292821653, 234.78240941259153, 242.68271525235355, 263.94129184100416, 267.23391429949004, 244.91045555210513, 239.39216339239016, 251.1572051108133, 253.29290337343096, 245.67941577863493, 209.41811176124477, 188.00933046221235]\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\ndef split_dataset(data):\n    \u0027\u0027\u0027\n    该函数实现以日为单位切分训练数据和测试数据\n    \u0027\u0027\u0027\n    # train \u003d dataset[23:35063]\n    # test \u003d dataset[35063:-2]\n    train \u003d dataset[1702:30982]\n    test \u003d dataset[30982:36718]\n    train \u003d np.array(np.split(train, len(train)/24)) # 将数据划分为按天为单位的数据\n    test \u003d np.array(np.split(test, len(test)/24))\n    # train.shape\n    # train.head(10)\n    # test.tail(10)\n    return train, test\n\n\ndef evaluate_forecasts(actual, predicted):\n    #统计24小时所有rmse\n    scores \u003d list()\n    MAE \u003d list()\n    for i in range(actual.shape[1]):\n        mse \u003d skm.mean_squared_error(actual[:, i], predicted[:, i])\n        rmse \u003d math.sqrt(mse)\n        scores.append(rmse)\n        x \u003d skm.mean_absolute_error(actual[:, i], predicted[:, i])\n        MAE.append(x)\n    \n    s \u003d 0 # 计算总的 RMSE\n    for row in range(actual.shape[0]):\n        for col in range(actual.shape[1]):\n            s +\u003d (actual[row, col] - predicted[row, col]) ** 2\n    score \u003d math.sqrt(s / (actual.shape[0] * actual.shape[1]))\n    print(\u0027actual.shape[0]:{}, actual.shape[1]:{}\u0027.format(actual.shape[0], actual.shape[1]))\n    return score, scores, MAE\n\ndef summarize_scores(name, score, scores,MAE):\n    s_scores \u003d \u0027, \u0027.join([\u0027%.1f\u0027 % s for s in scores])\n    print(\u0027%s: [%.3f] %s\\n\u0027 % (name, score, s_scores))\n    print(MAE)\n    \ndef sliding_window(train, sw_width\u003d24, n_out\u003d24, in_start\u003d0):\n    \n    data \u003d train.reshape((train.shape[0] * train.shape[1], train.shape[2])) # 将以周为单位的样本展平为以天为单位的序列\n    X, y \u003d [], []\n    \n    for _ in range(len(data)):\n        in_end \u003d in_start + sw_width\n        out_end \u003d in_end + n_out\n        \n        # 保证截取样本完整，最大元素索引不超过原序列索引，则截取数据；否则丢弃该样本\n        if out_end \u003c len(data):\n            # 训练数据以滑动步长1截取\n            train_seq \u003d data[in_start:in_end, 0]\n            train_seq \u003d train_seq.reshape((len(train_seq), 1))\n            X.append(train_seq)\n            y.append(data[in_end:out_end, 0])\n        in_start +\u003d 1\n        \n    return np.array(X), np.array(y)\n\ndef lstm_model(train, sw_width, in_start\u003d0, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4):\n    \u0027\u0027\u0027\n    该函数定义 Encoder-Decoder LSTM 模型\n    \u0027\u0027\u0027\n    train_x, train_y \u003d sliding_window(train, sw_width, in_start\u003d0)\n    \n    n_timesteps, n_features, n_outputs \u003d train_x.shape[1], train_x.shape[2], train_y.shape[1]\n    \n    train_y \u003d train_y.reshape((train_y.shape[0], train_y.shape[1], 1))\n    \n    model \u003d Sequential()\n    model.add(LSTM(200, activation\u003d\u0027relu\u0027,\n                   input_shape\u003d(n_timesteps, n_features)))\n    model.add(RepeatVector(n_outputs))\n    model.add(LSTM(200, activation\u003d\u0027relu\u0027, return_sequences\u003dTrue))\n    model.add(TimeDistributed(Dense(100, activation\u003d\u0027relu\u0027)))\n    model.add(TimeDistributed(Dense(1)))\n    \n    model.compile(loss\u003d\u0027mse\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])\n    print(model.summary())\n    \n    model.fit(train_x, train_y,\n              epochs\u003depochs_num, batch_size\u003dbatch_size_set, verbose\u003dverbose_set)\n    return model\n\n\ndef forecast(model, pred_seq, sw_width):\n    \u0027\u0027\u0027\n    该函数实现对输入数据的预测\n    \u0027\u0027\u0027\n    data \u003d np.array(pred_seq)\n    data \u003d data.reshape((data.shape[0]*data.shape[1], data.shape[2]))\n    \n    input_x \u003d data[-sw_width:, 0] # 获取输入数据的最后一周的数据\n    input_x \u003d input_x.reshape((1, len(input_x), 1)) # 重塑形状[1, sw_width, 1]\n    \n    yhat \u003d model.predict(input_x, verbose\u003d0) # 预测下周数据\n    yhat \u003d yhat[0] # 获取预测向量\n    return yhat\n\ndef evaluate_model(model, train, test, sd_width):\n    \u0027\u0027\u0027\n    该函数实现模型评估\n    \u0027\u0027\u0027\n    history_fore \u003d [x for x in train]\n    predictions \u003d list() # 用于保存每周的前向验证结果；\n    for i in range(len(test)):\n        yhat_sequence \u003d forecast(model, history_fore, sd_width) # 预测下周的数据\n        predictions.append(yhat_sequence) # 保存预测结果\n        history_fore.append(test[i, :]) # 得到真实的观察结果并添加到历史中以预测下周\n    \n    predictions \u003d np.array(predictions) \n    score, scores, MAE\u003d evaluate_forecasts(test[:, :, 0], predictions)\n    return score, scores, MAE\n\ndef model_plot(score, scores, days, name):\n    \u0027\u0027\u0027\n    该函数实现绘制RMSE曲线图\n    \u0027\u0027\u0027\n    plt.figure(figsize\u003d(8,6), dpi\u003d150)\n    plt.plot(days, scores, marker\u003d\u0027o\u0027, label\u003dname)\n    plt.grid(linestyle\u003d\u0027--\u0027, alpha\u003d0.5)\n    plt.ylabel(r\u0027$RMSE$\u0027, size\u003d15)\n    plt.title(\u0027Enco-Deco_LSTM \u0027,  size\u003d18)\n    plt.legend()\n    plt.show()\n    \n# def main_run(dataset, sw_width, days, name, in_start, verbose, epochs, batch_size):\n#     \u0027\u0027\u0027\n#     主函数：数据处理、模型训练流程\n#     \u0027\u0027\u0027\n#     # 划分训练集和测试集\n#     train, test \u003d split_dataset(dataset.values)\n#     # 训练模型\n#     model \u003d lstm_model(train, sw_width, in_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n#     # 计算RMSE\n#     score, scores \u003d evaluate_model(model, train, test, sw_width)\n#     # 打印分数\n#     summarize_scores(name, score, scores)\n#     # 绘图\n#     model_plot(score, scores, days, name)\n\n    \nif __name__ \u003d\u003d \u0027__main__\u0027:\n    \n    \n    dataset \u003d pd.read_csv(\u0027./LD_MT200_hour.csv\u0027, header\u003d0,\n                      low_memory\u003dFalse, infer_datetime_format\u003dTrue, engine\u003d\u0027c\u0027, index_col\u003d[\u0027date\u0027])\n    values \u003d dataset.values.astype(\u0027float32\u0027)\n    dataset[\u0027ELE_SUM\u0027] \u003d (values[:,1] + values[:,2] + values[:,3] + values[:,4] + values[:,5] + values[:,6])\n    \n    \n    \n    \n    train, test \u003d split_dataset(dataset.values)\n    \n    # hours \u003d [\u00270\u0027,\u00271\u0027,\u00272\u0027,\u00272\u0027,\u00274\u0027,\u00275\u0027,\u00276\u0027,\u00277\u0027,\u00278\u0027,\u00279\u0027,\u002710\u0027,\u002711\u0027,\u002712\u0027,\u002713\u0027,\u002714\u0027,\u002715\u0027,\u002716\u0027,\u002717\u0027,\u002718\u0027,\u002719\u0027,\u002720\u0027,\u002721\u0027,\u002722\u0027,\u002723\u0027]\n    name \u003d \u0027en-de-lstm\u0027\n    \n    sliding_window_width\u003d 24\n    input_sequence_start\u003d0\n    \n    epochs_num\u003d70\n    batch_size_set\u003d16\n    verbose_set\u003d0\n    \n    model \u003d lstm_model(train, sliding_window_width, input_sequence_start, verbose_set\u003d0, epochs_num\u003d20, batch_size_set\u003d4)\n    test.shape\n    score, scores, MAE \u003d evaluate_model(model, train, test, sliding_window_width)\n    \n    \n    # db \u003d pymysql.connect(host\u003d\"localhost\", user\u003d\"root\", password\u003d\"LQW1107@python\", database\u003d\"modeldata\",charset\u003d\"utf8\")\n    # cursor \u003d db.cursor()\n    # sql \u003d \"insert into modelinfo values \u003d (\" + name + \u0027,\u0027 + score + \u0027,\u0027 +MAE \n    # cursor.execute(sql)\n    \n    summarize_scores(name, score, scores, MAE)\n    \n    # main_run(dataset, sliding_window_width, days, name, input_sequence_start,\n    #          verbose_set, epochs_num, batch_size_set)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}